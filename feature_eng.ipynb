{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering using orders and vendors information ###\n",
    "\n",
    "During our initial analysis we decided to remove many columns from train_full. Here we will be adding in columns based on vendor and order information that matches with the customer and vendor in question. \n",
    "\n",
    "Below is a list of features we want to add: \n",
    "- Has ordered here before: binary (orders.csv) \n",
    "- Grand total: Average across customer’s order from vendor. (orders.csv) \n",
    "- Is_favorite: Set missing equal to 0, 1 otherwise. (orders.csv) \n",
    "- Distance between customer location and vendor location (train_full) \n",
    "- Number of times customer has ordered from this vendor tag (orders.csv) \n",
    "- One-hot encoding of vendor tag (train_full/vendors.csv) \n",
    "- Is_rated and vendor_rating (orders.csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/xpbsmtsx0xzbs7_6z34b_5yr0000gn/T/ipykernel_11787/986147297.py:5: DtypeWarning: Columns (15,16,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  orders = pd.read_csv('data/orders.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in CSV\n",
    "orders = pd.read_csv('data/orders.csv')\n",
    "vendors = pd.read_csv('data/vendors.csv')\n",
    "training_data = pd.read_csv('data/sm_train_full.csv')\n",
    "# training_data = pd.read_csv('data/lg_train_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing columns dropped from training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up dataframes columns\n",
      "Index(['akeed_order_id', 'customer_id', 'item_count', 'grand_total',\n",
      "       'payment_mode', 'promo_code', 'vendor_discount_amount',\n",
      "       'promo_code_discount_percentage', 'is_favorite', 'is_rated',\n",
      "       'vendor_rating', 'driver_rating', 'deliverydistance', 'preparationtime',\n",
      "       'delivery_time', 'order_accepted_time', 'driver_accepted_time',\n",
      "       'ready_for_pickup_time', 'picked_up_time', 'delivered_time',\n",
      "       'delivery_date', 'vendor_id', 'created_at', 'LOCATION_NUMBER',\n",
      "       'LOCATION_TYPE', 'CID X LOC_NUM X VENDOR'],\n",
      "      dtype='object')\n",
      "Index(['id', 'latitude', 'longitude', 'vendor_category_id', 'delivery_charge',\n",
      "       'serving_distance', 'prepration_time', 'discount_percentage', 'status',\n",
      "       'verified', 'vendor_rating', 'vendor_tag', 'vendor_tag_name',\n",
      "       'created_at', 'updated_at'],\n",
      "      dtype='object')\n",
      "Index(['customer_id', 'location_number', 'latitude_x', 'longitude_x', 'id',\n",
      "       'latitude_y', 'longitude_y', 'vendor_category_id', 'delivery_charge',\n",
      "       'serving_distance', 'prepration_time', 'discount_percentage',\n",
      "       'vendor_rating', 'vendor_tag', 'vendor_tag_name', 'location_number_obj',\n",
      "       'id_obj', 'CID X LOC_NUM X VENDOR', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Gathering the list of columns we removed from train_full.csv\n",
    "columns = ['is_open', 'status_y', 'device_type', 'verified_y', 'commission', 'is_akeed_delivering', 'language', 'open_close_flags', 'one_click_vendor', 'country_id', 'city_id', 'display_orders', 'gender', 'location_type', 'OpeningTime', 'OpeningTime2', 'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2', 'primary_tags', 'status_x', 'verified_x', 'created_at_x', 'updated_at_x', 'authentication_id', 'vendor_category_en', 'rank', 'created_at_y', 'updated_at_y']\n",
    "\n",
    "# Drop columns from the dataframes if they were removed from train_full.csv\n",
    "for col in columns:\n",
    "    if col in orders.columns:\n",
    "        orders = orders.drop(col, axis=1)\n",
    "    if col in vendors.columns:\n",
    "        vendors = vendors.drop(col, axis=1)\n",
    "    \n",
    "        \n",
    "# Drop rows in orders where the location_number != 0\n",
    "orders = orders[orders['LOCATION_NUMBER'] == 0]\n",
    "\n",
    "print(\"Cleaned up dataframes columns\")\n",
    "print(orders.columns)\n",
    "print(vendors.columns)\n",
    "\n",
    "temp = training_data.copy()\n",
    "\n",
    "print(training_data.columns)\n",
    "# print(lg_train.columns)\n",
    "\n",
    "# print(orders['LOCATION_NUMBER'].value_counts())\n",
    "# print(orders['is_rated'].value_counts())\n",
    "# print(orders['vendor_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to be used in the code\n",
    "column_name = 'CID X LOC_NUM X VENDOR'\n",
    "\n",
    "# Ensure the columns are treated as strings\n",
    "orders[column_name] = orders[column_name].astype(str)\n",
    "temp[column_name] = temp[column_name].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Has Ordered Before\n",
    "- Binary indicated customer has ordered from here before (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id  id  ordered_before\n",
      "0     TCHWPBT   4               0\n",
      "1     TCHWPBT  13               0\n",
      "2     TCHWPBT  28               0\n",
      "3     TCHWPBT  33               0\n",
      "4     TCHWPBT  43               0\n",
      "ordered_before\n",
      "0    423007\n",
      "1      4398\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add the 'ordered_before' column to dataframe and initialize with 0\n",
    "temp['ordered_before'] = 0\n",
    "\n",
    "# # Iterate through each row in orders dataframe\n",
    "# for index, row in orders.iterrows():\n",
    "#     if row[column_name] in orders[column_name].values:\n",
    "#         temp.at[index, 'ordered_before'] = 1\n",
    "\n",
    "# Replacing for-loop to make better use of pandas\n",
    "temp = temp.merge(\n",
    "    orders[[column_name]].drop_duplicates(),  # Assuming 'column_name' is the key linking temp and orders\n",
    "    on=column_name,\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "temp['ordered_before'] = (temp['_merge'] == 'both').astype(int)\n",
    "temp.drop(columns=['_merge'], inplace=True) \n",
    "\n",
    "\n",
    "# Print the first few rows of the updated orders dataframe to verify\n",
    "print(temp[['customer_id', 'id', 'ordered_before']].head(5))\n",
    "\n",
    "# Print value counts for ordered before\n",
    "print(temp['ordered_before'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Average total by customer and vendor\n",
    "- Numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25450\n",
      "  customer_id  id  vendor_average  customer_average\n",
      "0     TCHWPBT   4       16.856517               5.4\n",
      "1     TCHWPBT  13       18.324214               5.4\n",
      "2     TCHWPBT  28       12.308660               5.4\n",
      "3     TCHWPBT  33       22.147441               5.4\n",
      "4     TCHWPBT  43       12.038301               5.4\n"
     ]
    }
   ],
   "source": [
    "# Create new columns\n",
    "temp['vendor_average'] = 0\n",
    "temp['customer_average'] = 0\n",
    "\n",
    "# Calculate the average total cost by vendor and customer\n",
    "vendor_avg = orders.groupby('vendor_id')['grand_total'].mean().to_dict()\n",
    "customer_avg = orders.groupby('customer_id')['grand_total'].mean().to_dict()\n",
    "\n",
    "print(len(customer_avg))\n",
    "\n",
    "# Add the 'vendor_average' and 'customer_average' columns to dataframe\n",
    "temp['vendor_average'] = temp['id'].map(vendor_avg).fillna(0)\n",
    "temp['customer_average'] = temp['customer_id'].map(customer_avg).fillna(0)\n",
    "\n",
    "print(temp[['customer_id', 'id', 'vendor_average', 'customer_average']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Favorite Vendor\n",
    "- Binary. 1 if favorited, 0 if not or null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id  id  is_favorite\n",
      "0     TCHWPBT   4            0\n",
      "1     TCHWPBT  13            0\n",
      "2     TCHWPBT  28            0\n",
      "3     TCHWPBT  33            0\n",
      "4     TCHWPBT  43            0\n",
      "is_favorite\n",
      "0    427331\n",
      "1        74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add the column to dataframe and initialize with 0\n",
    "temp['is_favorite'] = 0\n",
    "\n",
    "# Filter to only include orders that have been rated\n",
    "fav_orders = orders[orders['is_favorite'] == 'Yes']  # Filter orders marked as favorite\n",
    "\n",
    "# Create temp dataset to merge with fav_orders\n",
    "temp = temp.merge(\n",
    "    fav_orders[[column_name]].drop_duplicates(),\n",
    "    on=column_name,\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "temp['is_favorite'] = (temp['_merge'] == 'both').astype(int)\n",
    "temp.drop(columns=['_merge'], inplace=True)\n",
    "        \n",
    "print(temp[['customer_id', 'id', 'is_favorite']].head(5))\n",
    "print(temp['is_favorite'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Number of times customer has ordered from vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id  id  times_ordered\n",
      "0     TCHWPBT   4              0\n",
      "1     TCHWPBT  13              0\n",
      "2     TCHWPBT  28              0\n",
      "3     TCHWPBT  33              0\n",
      "4     TCHWPBT  43              0\n",
      "Counts for number of times ordered:\n",
      "times_ordered\n",
      "0     423007\n",
      "1       3175\n",
      "2        660\n",
      "3        247\n",
      "4        114\n",
      "5         82\n",
      "6         49\n",
      "7         20\n",
      "8         19\n",
      "11         8\n",
      "9          7\n",
      "10         6\n",
      "14         2\n",
      "17         2\n",
      "13         2\n",
      "12         2\n",
      "51         1\n",
      "22         1\n",
      "15         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add the column to dataframe and initialize with 0\n",
    "temp['times_ordered'] = 0\n",
    "\n",
    "# Count number of times customer has ordered from a specific vendor\n",
    "number_times = orders.groupby(column_name).size().to_dict()\n",
    "\n",
    "# Map values to dataset\n",
    "temp['times_ordered'] = temp[column_name].map(number_times).fillna(0).astype(int)\n",
    "\n",
    "print(temp[['customer_id', 'id', 'times_ordered']].head(5))\n",
    "\n",
    "target_counts = temp['times_ordered'].value_counts()\n",
    "print(\"Counts for number of times ordered:\")\n",
    "print(target_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Vendor Rating\n",
    "- Binary if a customer has (1) or has not (0) rated the vendor.\n",
    "- Vendor rating from customer, 0 if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/xpbsmtsx0xzbs7_6z34b_5yr0000gn/T/ipykernel_11787/675471179.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rated_orders.rename(columns={'vendor_rating': 'rating'}, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id  id  customer_rating  is_rated\n",
      "0     TCHWPBT   4              0.0         0\n",
      "1     TCHWPBT  13              0.0         0\n",
      "2     TCHWPBT  28              0.0         0\n",
      "3     TCHWPBT  33              0.0         0\n",
      "4     TCHWPBT  43              0.0         0\n",
      "is_rated\n",
      "0    426875\n",
      "1       672\n",
      "Name: count, dtype: int64\n",
      "customer_rating\n",
      "0.0    426875\n",
      "5.0       439\n",
      "4.0       113\n",
      "3.0        55\n",
      "1.0        41\n",
      "2.0        24\n",
      "Name: count, dtype: int64\n",
      "Index(['customer_id', 'location_number', 'latitude_x', 'longitude_x', 'id',\n",
      "       'latitude_y', 'longitude_y', 'vendor_category_id', 'delivery_charge',\n",
      "       'serving_distance', 'prepration_time', 'discount_percentage',\n",
      "       'vendor_rating', 'vendor_tag', 'vendor_tag_name', 'location_number_obj',\n",
      "       'id_obj', 'CID X LOC_NUM X VENDOR', 'target', 'ordered_before',\n",
      "       'vendor_average', 'customer_average', 'is_favorite', 'times_ordered',\n",
      "       'is_rated', 'customer_rating'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Add the columns to dataframe and initialize with 0\n",
    "temp['is_rated'] = 0\n",
    "temp['customer_rating'] = 0\n",
    "\n",
    "# Filter orders where customer rated the vendor\n",
    "rated_orders = orders[orders['is_rated'] == 'Yes']\n",
    "\n",
    "# Rename column to avoid confusion\n",
    "rated_orders.rename(columns={'vendor_rating': 'rating'}, inplace=True) \n",
    "\n",
    "# Merge rated_orders with temp dataset\n",
    "temp = temp.merge(\n",
    "    rated_orders[[column_name, 'rating']],  # Only include relevant columns\n",
    "    on=column_name,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Replace missing customer ratings with 0 (indicating no rating given)\n",
    "temp['customer_rating'] = temp['rating'].fillna(0)\n",
    "\n",
    "# Update 'is_rated' column to reflect whether the customer rated the vendor\n",
    "temp['is_rated'] = temp['customer_rating'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "temp.drop(columns=['rating'], inplace=True)\n",
    "\n",
    "# Print results\n",
    "print(temp[['customer_id', 'id', 'customer_rating', 'is_rated']].head(5))\n",
    "print(temp['is_rated'].value_counts())\n",
    "print(temp['customer_rating'].value_counts())\n",
    "print(temp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Distance\n",
    "- Distance from customer's location to vendor's location\n",
    "- Serving distance from vendors.csv\n",
    "\n",
    "_Note: Since the locations have been masked this may need to be normalized to a range to show some relationship._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance before transofrmation:\n",
      "count    427547.000000\n",
      "mean         33.978695\n",
      "std          41.820776\n",
      "min           0.000540\n",
      "25%           0.703821\n",
      "50%           1.491614\n",
      "75%          79.047070\n",
      "max        1044.847837\n",
      "Name: distance, dtype: float64\n",
      "Distance column information:\n",
      "count    427547.000000\n",
      "mean          6.057566\n",
      "std           3.519171\n",
      "min           2.000000\n",
      "25%           2.995439\n",
      "50%           3.706129\n",
      "75%          10.194278\n",
      "max          15.000000\n",
      "Name: distance_scaled, dtype: float64\n",
      "Generated serving_distance column information:\n",
      "count    427547.000000\n",
      "mean         11.087298\n",
      "std           3.321123\n",
      "min           7.013438\n",
      "25%           8.175455\n",
      "50%           9.005072\n",
      "75%          15.000000\n",
      "max          15.000000\n",
      "Name: serving_distance, dtype: float64\n",
      "  customer_id  id  distance  distance_scaled  serving_distance\n",
      "0     TCHWPBT   4  4.774880        10.927795              15.0\n",
      "1     TCHWPBT  13  4.775635        10.929208              15.0\n",
      "2     TCHWPBT  28  4.781257        10.939721              15.0\n",
      "3     TCHWPBT  33  4.775470        10.928899              15.0\n",
      "4     TCHWPBT  43  4.777126        10.931996              15.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the distance column\n",
    "temp['distance'] = 0\n",
    "\n",
    "# Euclidean distance\n",
    "temp['distance'] = np.sqrt((temp['latitude_x'] - temp['latitude_y'])**2 + (temp['longitude_x'] - temp['longitude_y'])**2)\n",
    "\n",
    "print(\"Distance before transofrmation:\")\n",
    "print(temp['distance'].describe())\n",
    "\n",
    "# Apply a log transformation\n",
    "temp['distance'] = np.log1p(temp['distance'])\n",
    "\n",
    "# Calculate the statistics for transformation\n",
    "distance_min = temp['distance'].min()\n",
    "distance_max = temp['distance'].max()\n",
    "distance_mean = temp['distance'].mean()\n",
    "distance_std = temp['distance'].std()\n",
    "\n",
    "serving_distance_mean = vendors['serving_distance'].mean()\n",
    "serving_distance_std = vendors['serving_distance'].std()\n",
    "\n",
    "# Rescale the distance column to match serving_distance range [2, 15]\n",
    "temp['distance_scaled'] = 2 + (temp['distance'] - distance_min) / (distance_max - distance_min) * (15 - 2)\n",
    "\n",
    "# Match mean and std of serving_distance\n",
    "temp['serving_distance'] = serving_distance_mean + ((temp['distance_scaled'] - temp['distance_scaled'].mean()) / \n",
    "                                                       temp['distance_scaled'].std()) * serving_distance_std\n",
    "\n",
    "# Clip values to the maximum serving distance (optional)\n",
    "temp['serving_distance'] = temp['serving_distance'].clip(upper=15)\n",
    "\n",
    "print(\"Distance column information:\")\n",
    "print(temp['distance_scaled'].describe())\n",
    "\n",
    "# Final summary statistics of the generated serving_distance column\n",
    "print(\"Generated serving_distance column information:\")\n",
    "print(temp['serving_distance'].describe())\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(temp[['customer_id', 'id', 'distance', 'distance_scaled', 'serving_distance']].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Vendor Tags\n",
    "If a customer has ordered a matching vendor tag to the vendor given. \n",
    "The number of matching tags in customers history to current vendor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id  location_number  latitude_x  longitude_x  id  latitude_y  \\\n",
      "0     TCHWPBT                0      -96.44        -67.2   4     -0.5884   \n",
      "1     TCHWPBT                0      -96.44        -67.2  13     -0.4717   \n",
      "2     TCHWPBT                0      -96.44        -67.2  28      0.4807   \n",
      "3     TCHWPBT                0      -96.44        -67.2  33     -0.4946   \n",
      "4     TCHWPBT                0      -96.44        -67.2  43     -0.1150   \n",
      "\n",
      "   longitude_y  vendor_category_id  delivery_charge  serving_distance  ...  \\\n",
      "0       0.7544                 2.0              0.0              15.0  ...   \n",
      "1       0.7446                 2.0              0.7              15.0  ...   \n",
      "2       0.5527                 2.0              0.7              15.0  ...   \n",
      "3       0.7430                 2.0              0.7              15.0  ...   \n",
      "4       0.5460                 2.0              0.7              15.0  ...   \n",
      "\n",
      "   vendor_average  customer_average  is_favorite times_ordered is_rated  \\\n",
      "0       16.856517               5.4            0             0        0   \n",
      "1       18.324214               5.4            0             0        0   \n",
      "2       12.308660               5.4            0             0        0   \n",
      "3       22.147441               5.4            0             0        0   \n",
      "4       12.038301               5.4            0             0        0   \n",
      "\n",
      "   customer_rating  distance distance_scaled  ordered_vendor_tag  \\\n",
      "0              0.0  4.774880       10.927795                   1   \n",
      "1              0.0  4.775635       10.929208                   1   \n",
      "2              0.0  4.781257       10.939721                   1   \n",
      "3              0.0  4.775470       10.928899                   1   \n",
      "4              0.0  4.777126       10.931996                   1   \n",
      "\n",
      "   matching_tags_count  \n",
      "0                    8  \n",
      "1                    9  \n",
      "2                    1  \n",
      "3                    4  \n",
      "4                    6  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "  customer_id  id  ordered_vendor_tag  matching_tags_count\n",
      "0     TCHWPBT   4                   1                    8\n",
      "1     TCHWPBT  13                   1                    9\n",
      "2     TCHWPBT  28                   1                    1\n",
      "3     TCHWPBT  33                   1                    4\n",
      "4     TCHWPBT  43                   1                    6\n"
     ]
    }
   ],
   "source": [
    "# New features\n",
    "temp['ordered_vendor_tag'] = 0\n",
    "temp['matching_tags_count'] = 0\n",
    "\n",
    "vendors['vendor_tag'] = vendors['vendor_tag'].fillna('')  # Replace NaN with empty string\n",
    "\n",
    "# Create mapping of vendor id to tags\n",
    "# vendors['vendor_tag'] = vendors['vendor_tag'].apply(lambda x: set(map(int, x.split(','))) if x else set())\n",
    "vendor_tags = dict(zip(vendors['id'], vendors['vendor_tag']))\n",
    "\n",
    "# Tags customers have ordered\n",
    "customer_tags = {}\n",
    "\n",
    "# For each order, map the vendor's tags to the customer\n",
    "for idx, row in orders.iterrows():\n",
    "    customer_id = row['customer_id']\n",
    "    vendor_id = row['vendor_id']\n",
    "    if vendor_id in vendor_tags:  # Ensure the vendor exists in vendors_df\n",
    "        tags = vendor_tags[vendor_id]\n",
    "        if customer_id not in customer_tags:\n",
    "            customer_tags[customer_id] = set(tags)\n",
    "        else:\n",
    "            customer_tags[customer_id].update(tags)\n",
    "\n",
    "def calculate_tag_columns(row):\n",
    "    customer_id = row['customer_id']\n",
    "    vendor_id = row['id']\n",
    "    \n",
    "    # Get the vendor's tags\n",
    "    vendor_tags_set = vendor_tags.get(vendor_id, set())\n",
    "    \n",
    "    # Get the customer's ordered tags\n",
    "    customer_tags_set = customer_tags.get(customer_id, set())\n",
    "    \n",
    "    # Calculate the matching tags\n",
    "    matching_tags = customer_tags_set.intersection(vendor_tags_set)\n",
    "    ordered_vendor_tag = 1 if matching_tags else 0\n",
    "    matching_tags_count = len(matching_tags)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'ordered_vendor_tag': ordered_vendor_tag,\n",
    "        'matching_tags_count': matching_tags_count\n",
    "    })\n",
    "\n",
    "# Apply the function to train_full_df\n",
    "temp[['ordered_vendor_tag', 'matching_tags_count']] = temp.apply(calculate_tag_columns, axis=1)\n",
    "\n",
    "print(temp.head())\n",
    "print(temp[['customer_id', 'id', 'ordered_vendor_tag', 'matching_tags_count']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The locations being transformed this way may become an issue, but it now more closely represents the findings in 'serving_distance'\n",
    "\n",
    "Before saving the dataset we will remove: 'vendor_tag', 'vendor_tag_name', 'CID X LOC_NUM X VENDOR' and make sure out small and large dataset contain the same columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final columns in dataframe:\n",
      "Index(['customer_id', 'latitude_x', 'longitude_x', 'vendor_id', 'latitude_y',\n",
      "       'longitude_y', 'vendor_category_id', 'delivery_charge',\n",
      "       'serving_distance', 'prepration_time', 'discount_percentage',\n",
      "       'vendor_rating', 'target', 'ordered_before', 'vendor_average',\n",
      "       'customer_average', 'is_favorite', 'times_ordered', 'is_rated',\n",
      "       'customer_rating', 'distance', 'distance_scaled', 'ordered_vendor_tag',\n",
      "       'matching_tags_count'],\n",
      "      dtype='object')\n",
      "(427547, 24)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that are no longer needed\n",
    "final_drop_cols = ['location_number_obj', 'id_obj','vendor_tag', 'vendor_tag_name', 'CID X LOC_NUM X VENDOR', 'location_number']\n",
    "\n",
    "# Rename id to vendor_id\n",
    "temp = temp.rename(columns={'id': 'vendor_id'})\n",
    "\n",
    "for col in final_drop_cols:\n",
    "    if col in temp.columns:\n",
    "        temp = temp.drop(col, axis=1)\n",
    "    \n",
    "print(\"Final columns in dataframe:\")\n",
    "print(temp.columns)\n",
    "print(temp.shape)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "# temp.to_csv('data/new_sm_train.csv', index=False) # For smaller dataset\n",
    "# temp.to_csv('data/new_train.csv', index=False) # For larger dataset\n",
    "\n",
    "# Confirm that the number of columns in the new CSV file is the same as the original\n",
    "new_sm = pd.read_csv('data/new_sm_train.csv')\n",
    "print(len(new_sm.columns) == len(temp.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
